{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from unity_dataset import UnityDataset\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "IMG_SIZE = (480, 360)\n",
    "PATCH_SIZE = (24, 40)\n",
    "\n",
    "TRAIN_SET_PERCENT = 0.8\n",
    "TEST_SET_LENGTH = 1\n",
    "\n",
    "INPUT_IMAGE_DIR = \"/media/blooker/Storage/gold-project-2021-images/480p-refactor-office-x4\"\n",
    "\n",
    "OUTPUT_IMAGE_DIR = \"data/Data/Img\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset = UnityDataset(root_dir=INPUT_IMAGE_DIR,\n",
    "                       lit_folder='2',\n",
    "                       unlit_folder='1',\n",
    "                       depth_folder='0',\n",
    "                       csv_file='0.csv',\n",
    "                       img_size=IMG_SIZE,\n",
    "                       patch_size=PATCH_SIZE,\n",
    "                       transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "dataset_len = len(dataset)\n",
    "\n",
    "train_set_length = int((dataset_len - TEST_SET_LENGTH) * TRAIN_SET_PERCENT)\n",
    "val_set_length = (dataset_len - TEST_SET_LENGTH) - train_set_length\n",
    "\n",
    "lengths = [train_set_length, val_set_length, TEST_SET_LENGTH]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = torch.utils.data.random_split(dataset, lengths)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def make_dir():\n",
    "    if not os.path.exists(OUTPUT_IMAGE_DIR):\n",
    "        os.makedirs(OUTPUT_IMAGE_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # params encoder\n",
    "        self.enc_params1 = nn.Linear(3, 160)\n",
    "        self.enc_params2 = nn.Linear(160, 420)\n",
    "        self.enc_params3 = nn.Linear(420, 1350)\n",
    "\n",
    "        # patch encoder\n",
    "        self.enc_patch1 = nn.Linear(1, 25)\n",
    "        self.enc_patch2 = nn.Linear(25, 60)\n",
    "        self.enc_patch3 = nn.Linear(60, 90)\n",
    "\n",
    "        # params_patch encoder\n",
    "        self.enc_params_patch1 = nn.Conv2d(in_channels=6, out_channels=6, kernel_size=1)\n",
    "        self.enc_params_patch2 = nn.Conv2d(in_channels=6, out_channels=22, kernel_size=3, padding=1)\n",
    "        self.enc_params_patch3 = nn.Conv2d(in_channels=22, out_channels=38, kernel_size=3, padding=1)\n",
    "        self.enc_params_patch4 = nn.Conv2d(in_channels=38, out_channels=70, kernel_size=3, padding=1)\n",
    "\n",
    "        # lit encoder\n",
    "        self.enc_lit1 = nn.Conv2d(in_channels=4, out_channels=4, kernel_size=1)\n",
    "        self.enc_lit2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, padding=1)\n",
    "\n",
    "        # decoder\n",
    "        self.dec1 = nn.Conv2d(in_channels=78, out_channels=78, kernel_size=1)\n",
    "\n",
    "        self.dec2 = nn.Conv2d(in_channels=78, out_channels=86, kernel_size=3, padding=1)\n",
    "        self.dec3 = nn.Conv2d(in_channels=86, out_channels=102, kernel_size=3, padding=1)\n",
    "        self.dec4 = nn.Conv2d(in_channels=102, out_channels=118, kernel_size=3, padding=1)\n",
    "        self.dec5 = nn.Conv2d(in_channels=118, out_channels=126, kernel_size=3, padding=1)\n",
    "\n",
    "        self.dec6 = nn.ConvTranspose2d(in_channels=126, out_channels=126, kernel_size=2, stride=2)\n",
    "\n",
    "        self.dec7 = nn.Conv2d(in_channels=126, out_channels=150, kernel_size=3, padding=1)\n",
    "        self.dec8 = nn.Conv2d(in_channels=150, out_channels=166, kernel_size=3, padding=1)\n",
    "        self.dec9 = nn.Conv2d(in_channels=166, out_channels=182, kernel_size=3, padding=1)\n",
    "\n",
    "        self.dec10 = nn.Conv2d(in_channels=182, out_channels=3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x_unlit, x_dep, x_params, x_patch):\n",
    "        # enc_params\n",
    "        x_params = F.relu(self.enc_params1(x_params))   # (b, 160)\n",
    "        x_params = F.relu(self.enc_params2(x_params))   # (b, 420)\n",
    "        x_params = F.relu(self.enc_params3(x_params))   # (b, 1350)\n",
    "\n",
    "        # enc_patch\n",
    "        x_patch = F.relu(self.enc_patch1(x_patch))  # (b, 25)\n",
    "        x_patch = F.relu(self.enc_patch2(x_patch))  # (b, 60)\n",
    "        x_patch = F.relu(self.enc_patch3(x_patch))  # (b, 90)\n",
    "\n",
    "        # Concatenate x_params and x_patch together\n",
    "        x_params_patch = torch.cat((x_params, x_patch), dim=1)  # (b, 1440)\n",
    "        x_params_patch = x_params_patch.reshape(-1, 6, 20, 12)      # (b, 8, 15, 12)\n",
    "\n",
    "        # enc_params_patch\n",
    "        x_params_patch = F.relu(self.enc_params_patch1(x_params_patch)) # (b, 6, 15, 12)\n",
    "        x_params_patch = F.relu(self.enc_params_patch2(x_params_patch)) # (b, 22, 15, 12)\n",
    "        x_params_patch = F.relu(self.enc_params_patch3(x_params_patch)) # (b, 38, 15, 12)\n",
    "        x_params_patch = F.relu(self.enc_params_patch4(x_params_patch)) # (b, 70, 15, 12)\n",
    "\n",
    "        # Concatenate x_unlit and x_dep to form x_lit\n",
    "        x_lit = torch.cat((x_unlit, x_dep), 1)  # (b, 4, 30, 24)\n",
    "\n",
    "        # lit encoder\n",
    "        x_lit = F.relu(self.enc_lit1(x_lit))                    # (b, 4, 30, 24)\n",
    "        x_lit = F.relu(self.enc_lit2(x_lit))                    # (b, 8, 30, 24)\n",
    "        x_lit = F.max_pool2d(x_lit, kernel_size=2, stride=2)    # (b, 8, 15, 12)\n",
    "\n",
    "        # Concatenate x_lit and x_params_patch\n",
    "        x_lit = torch.cat((x_lit, x_params_patch), 1)  # (b, 78, 15, 12)\n",
    "\n",
    "        # decoder\n",
    "        x_lit = F.relu(self.dec1(x_lit))        # (b, 78, 15, 12)\n",
    "        x_lit = F.relu(self.dec2(x_lit))        # (b, 86, 15, 12)\n",
    "        x_lit = F.relu(self.dec3(x_lit))        # (b, 102, 15, 12)\n",
    "        x_lit = F.relu(self.dec4(x_lit))        # (b, 118, 15, 12)\n",
    "        x_lit = F.relu(self.dec5(x_lit))        # (b, 126, 15, 12)\n",
    "\n",
    "        x_lit = F.relu(self.dec6(x_lit))        # (b, 126, 30, 24)\n",
    "\n",
    "        x_lit = F.relu(self.dec7(x_lit))        # (b, 150, 30, 24)\n",
    "        x_lit = F.relu(self.dec8(x_lit))        # (b, 166, 30, 24)\n",
    "        x_lit = F.relu(self.dec9(x_lit))        # (b, 182, 30, 24)\n",
    "\n",
    "        x_lit = torch.sigmoid(self.dec10(x_lit)) # (b, 3, 30, 24)\n",
    "\n",
    "        return x_lit\n",
    "\n",
    "\n",
    "net = Autoencoder()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=LEARNING_RATE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def train(net, trainloader, validloader, NUM_EPOCHS):\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "\n",
    "    device = get_device()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        start_time = time.perf_counter()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "\n",
    "            training = phase == \"train\"\n",
    "\n",
    "            net.train(training)\n",
    "            if training:\n",
    "                loader = trainloader\n",
    "            else:\n",
    "                loader = validloader\n",
    "\n",
    "            for data in loader:\n",
    "                x, x_dep, x_params, x_patch, y = data\n",
    "\n",
    "                x = x.to(device, dtype=torch.float)\n",
    "                x_dep = x_dep.to(device, dtype=torch.float)\n",
    "                x_params = x_params.to(device, dtype=torch.float)\n",
    "                x_patch = x_patch.to(device, dtype=torch.float)\n",
    "\n",
    "                y = y.to(device, dtype=torch.float)\n",
    "\n",
    "                for sample in range(x.shape[0]):\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = net(x[sample], x_dep[sample], x_params[sample], x_patch[sample])\n",
    "                    loss = criterion(outputs, y[sample])\n",
    "\n",
    "                    if training:\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "            loss = running_loss / len(loader)\n",
    "\n",
    "            if training:\n",
    "                train_loss.append(loss)\n",
    "            else:\n",
    "                valid_loss.append(loss)\n",
    "\n",
    "            print(\"Epoch {} of {}, {} loss: {:.6f}, Time: {:.4f}\".format(\n",
    "                epoch+1, NUM_EPOCHS, phase, loss, time.perf_counter()-start_time\n",
    "            ))\n",
    "\n",
    "        print()\n",
    "\n",
    "    return train_loss, valid_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": "DataParallel(\n  (module): Autoencoder(\n    (enc_params1): Linear(in_features=3, out_features=160, bias=True)\n    (enc_params2): Linear(in_features=160, out_features=420, bias=True)\n    (enc_params3): Linear(in_features=420, out_features=1350, bias=True)\n    (enc_patch1): Linear(in_features=1, out_features=25, bias=True)\n    (enc_patch2): Linear(in_features=25, out_features=60, bias=True)\n    (enc_patch3): Linear(in_features=60, out_features=90, bias=True)\n    (enc_params_patch1): Conv2d(6, 6, kernel_size=(1, 1), stride=(1, 1))\n    (enc_params_patch2): Conv2d(6, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (enc_params_patch3): Conv2d(22, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (enc_params_patch4): Conv2d(38, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (enc_lit1): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n    (enc_lit2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (dec1): Conv2d(78, 78, kernel_size=(1, 1), stride=(1, 1))\n    (dec2): Conv2d(78, 86, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (dec3): Conv2d(86, 102, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (dec4): Conv2d(102, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (dec5): Conv2d(118, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (dec6): ConvTranspose2d(126, 126, kernel_size=(2, 2), stride=(2, 2))\n    (dec7): Conv2d(126, 150, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (dec8): Conv2d(150, 166, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (dec9): Conv2d(166, 182, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (dec10): Conv2d(182, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_device()\n",
    "print(device)\n",
    "\n",
    "net = nn.DataParallel(net)\n",
    "net.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 5, train loss: 0.194148, Time: 2.4726\n",
      "Epoch 1 of 5, val loss: 0.883588, Time: 2.6570\n",
      "\n",
      "Epoch 2 of 5, train loss: 0.131036, Time: 1.2366\n",
      "Epoch 2 of 5, val loss: 0.619791, Time: 1.4140\n",
      "\n",
      "Epoch 3 of 5, train loss: 0.081911, Time: 1.2290\n",
      "Epoch 3 of 5, val loss: 0.421500, Time: 1.3984\n",
      "\n",
      "Epoch 4 of 5, train loss: 0.083621, Time: 1.2412\n",
      "Epoch 4 of 5, val loss: 0.429595, Time: 1.4123\n",
      "\n",
      "Epoch 5 of 5, train loss: 0.081610, Time: 1.1861\n",
      "Epoch 5 of 5, val loss: 0.420153, Time: 1.3568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "make_dir()\n",
    "\n",
    "train_loss, valid_loss = train(net, train_loader, valid_loader, NUM_EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss)\n",
    "plt.plot(valid_loss)\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(\"./\" + OUTPUT_IMAGE_DIR + \"/deep_ae_loss.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Input to the model\n",
    "x = torch.randn(1, 3, PATCH_SIZE[1], PATCH_SIZE[0])\n",
    "x_dep = torch.randn(1, 1, PATCH_SIZE[1], PATCH_SIZE[0])\n",
    "x_params = torch.randn(1, 3)\n",
    "x_patch = torch.randn(1, 1)\n",
    "\n",
    "# Move the model from GPU to CPU before exporting\n",
    "net.cpu()\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(net.module,                           # model being run\n",
    "                  (x, x_dep, x_params, x_patch),        # model input (or a tuple for multiple inputs)\n",
    "                  \"./data/Data/model.onnx\",             # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,                   # store the trained parameter weights inside the model file\n",
    "                  opset_version=9,                      # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,             # whether to execute constant folding for optimization\n",
    "                  input_names = ['x_unlit',\n",
    "                                 'x_dep',\n",
    "                                 'x_params',\n",
    "                                 'x_patch'],            # the model's input names\n",
    "                  output_names = ['y']                  # the model's output name\n",
    "                  )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}